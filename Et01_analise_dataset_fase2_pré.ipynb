{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphaelCarvalh/BootCampAVANTI_machine_learning/blob/ativ04-et01-analise-dataset/Et01_analise_dataset_fase2_pr%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projeto Clothing Co-Parsing - Etapa 1 - Notebook: Análise do Dataset - TIV-04-ET-02\n"
      ],
      "metadata": {
        "id": "xB_DWEsu5T-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Projeto Clothing Co-Parsing - Notebook Principal (Professor)\n",
        "# ============================================================\n",
        "\n",
        "# 1. Instalação de pacotes necessários\n",
        "print(\"Instalando pacotes necessários...\")\n",
        "!pip install opendatasets pandas matplotlib opencv-python pillow --quiet\n",
        "print(\"Pacotes instalados com sucesso.\\n\")\n",
        "\n",
        "# 2. Importações iniciais\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time, copy, json\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Pacotes importados com sucesso.\\n\")\n",
        "\n",
        "# Otimização no CUDA\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojaVnMRr-9fR",
        "outputId": "79058cea-3d1a-4fe2-d82f-3003dd3c7225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando pacotes necessários...\n",
            "Pacotes instalados com sucesso.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Montar Google Drive e carregar dataset já limpo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "LOAD_PATH = \"/content/drive/MyDrive/ClothingDataset/df_clean.csv\"\n",
        "df = pd.read_csv(LOAD_PATH)\n",
        "\n",
        "print(\"Exemplo do dataset carregado:\")\n",
        "print(df.head())\n",
        "print(f\"Total de imagens: {len(df)}\\n\")\n",
        "\n",
        "# Número de classes\n",
        "num_classes = len(df['label'].unique())\n",
        "print(f\"Número de classes: {num_classes}\")\n"
      ],
      "metadata": {
        "id": "TE7vaTD-_BQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1536be75-4957-489b-c774-7d22d4ac4b71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Exemplo do dataset carregado:\n",
            "                                     image_path  corrupted        image_hash  \\\n",
            "0  ./clothing-coparsing-dataset/images/0391.jpg      False  b19bcb72550cccf0   \n",
            "1  ./clothing-coparsing-dataset/images/1465.jpg      False  8e2e7b911476a969   \n",
            "2  ./clothing-coparsing-dataset/images/1312.jpg      False  f18081ff763ac4f0   \n",
            "3  ./clothing-coparsing-dataset/images/1842.jpg      False  b14e84b14c9aae6f   \n",
            "4  ./clothing-coparsing-dataset/images/0983.jpg      False  b4ccdbb30489bcb4   \n",
            "\n",
            "   width  height  channels        label  \n",
            "0    550     824         3  pixel-level  \n",
            "1    550     809         3  image-level  \n",
            "2    550     832         3  image-level  \n",
            "3    550     809         3  image-level  \n",
            "4    550     827         3  pixel-level  \n",
            "Total de imagens: 2096\n",
            "\n",
            "Número de classes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Transformações e Augmentations\n",
        "print(\"Configurando transformações e augmentations...\\n\")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Transformações configuradas com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQqMqZ4B_Hg9",
        "outputId": "0c199a5e-6612-4c15-b70e-c82c6850186f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando transformações e augmentations...\n",
            "\n",
            "Transformações configuradas com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Dataset personalizado\n",
        "class ClothingDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx, 0], self.data[idx, 1]\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            # fallback para imagens corrompidas\n",
        "            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# 6. Split em treino, validação, teste\n",
        "train_data, temp_data = train_test_split(df.values, test_size=0.2, random_state=42, stratify=df.values[:,1])\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data[:,1])\n",
        "\n",
        "# Criar datasets\n",
        "train_ds = ClothingDataset(train_data, transform=train_transform)\n",
        "val_ds = ClothingDataset(val_data, transform=val_test_transform)\n",
        "test_ds = ClothingDataset(test_data, transform=val_test_transform)\n",
        "\n",
        "# Criar dataloaders\n",
        "BATCH_SIZE = 32\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Treino: {len(train_ds)} | Validação: {len(val_ds)} | Teste: {len(test_ds)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzaQ9EZw_Ji7",
        "outputId": "8f6b8414-9a5f-4e91-c445-ec13594de3a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: 1676 | Validação: 210 | Teste: 210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=10,\n",
        "    device=None,\n",
        "    save_path=\"best_model.pth\",\n",
        "    early_stopping_patience=None,\n",
        "    grad_clip=None,\n",
        "    use_amp=True\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if (use_amp and device.type == \"cuda\") else None\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print(f\"\\nÉpoca {epoch}/{num_epochs}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # ---------- Treino ----------\n",
        "        model.train()\n",
        "        train_loss, train_correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in tqdm(train_dl, desc=\"Treinando\", leave=False):\n",
        "            #inputs, labels = inputs.to(device), torch.tensor(labels, dtype=torch.long).to(device)\n",
        "            inputs, labels = inputs.to(device), labels.detach().clone().to(device, dtype=torch.long)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                if grad_clip:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                if grad_clip:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_correct += torch.sum(preds == labels).item()\n",
        "            total += inputs.size(0)\n",
        "\n",
        "        epoch_loss = train_loss / total\n",
        "        epoch_acc = train_correct / total\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_acc\"].append(epoch_acc)\n",
        "\n",
        "        # ---------- Validação ----------\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_dl:\n",
        "                #inputs, labels = inputs.to(device), torch.tensor(labels, dtype=torch.long).to(device)\n",
        "                inputs, labels = inputs.to(device), labels.detach().clone().to(device, dtype=torch.long)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                val_correct += torch.sum(preds == labels).item()\n",
        "                val_total += inputs.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Salvar melhor modelo\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_wts, save_path)\n",
        "            patience_counter = 0\n",
        "            print(f\" Melhor modelo salvo em {save_path}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if early_stopping_patience and patience_counter >= early_stopping_patience:\n",
        "                print(\" Early stopping ativado.\")\n",
        "                break\n",
        "\n",
        "        print(f\" Tempo da época: {(time.time()-start_time):.1f}s\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history, best_val_acc\n"
      ],
      "metadata": {
        "id": "DBpI-wKGW8Si"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformações e augmentations"
      ],
      "metadata": {
        "id": "XydGTCU9D7ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Definição dos modelos\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# ResNet50\n",
        "resnet50 = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "in_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(in_features, num_classes)\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "# EfficientNet-B0\n",
        "efficientnet = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
        "in_features = efficientnet.classifier[1].in_features\n",
        "efficientnet.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "print(\"Modelos inicializados com sucesso.\")\n",
        "\n",
        "# Critério de perda\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ---------- Treinar ResNet50 ----------\n",
        "optimizer_resnet = optim.Adam(resnet50.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando ResNet50...\")\n",
        "resnet50, history_resnet, best_acc_resnet = train_model(\n",
        "    model=resnet50,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_resnet,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_resnet50.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "# Exportar ResNet50\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "import shutil\n",
        "try:\n",
        "    shutil.copy2(\"/content/best_resnet50.pth\", os.path.join(EXPORT_PATH, \"best_resnet50.pth\"))\n",
        "    print(\"ResNet50 exportado com sucesso ✅\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao exportar ResNet50: {e}\")\n",
        "\n",
        "# ---------- Treinar EfficientNet-B0 ----------\n",
        "optimizer_efficient = optim.Adam(efficientnet.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando EfficientNet-B0...\")\n",
        "efficientnet, history_efficient, best_acc_efficient = train_model(\n",
        "    model=efficientnet,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_efficient,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_efficientnet.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "# Exportar EfficientNet-B0\n",
        "try:\n",
        "    shutil.copy2(\"/content/best_efficientnet.pth\", os.path.join(EXPORT_PATH, \"best_efficientnet.pth\"))\n",
        "    print(\"EfficientNet-B0 exportado com sucesso ✅\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao exportar EfficientNet: {e}\")\n",
        "\n",
        "# ---------- Comparação da Acurácia ----------\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history_resnet['val_acc'], label=\"ResNet50\")\n",
        "plt.plot(history_efficient['val_acc'], label=\"EfficientNet-B0\")\n",
        "plt.title(\"Comparação da Acurácia de Validação\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Resultados finais:\")\n",
        "print(f\"ResNet50 - Melhor Val Acc: {best_acc_resnet:.4f}\")\n",
        "print(f\"EfficientNet-B0 - Melhor Val Acc: {best_acc_efficient:.4f}\")\n"
      ],
      "metadata": {
        "id": "nYuT7PhOsUDQ",
        "outputId": "71218d98-1349-46c6-b226-12d812d98017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1266906226.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 6. Definição dos modelos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Usando dispositivo: {device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Definição dos modelos\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# ResNet50\n",
        "resnet50 = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "in_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(in_features, num_classes)\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "# EfficientNet-B0\n",
        "efficientnet = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
        "in_features = efficientnet.classifier[1].in_features\n",
        "efficientnet.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "# VGG16\n",
        "vgg16 = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
        "in_features = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Linear(in_features, num_classes)\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "print(\"Modelos inicializados com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjh_uGUfD6bi",
        "outputId": "c41f49f9-601d-4e6e-80f6-cb648061db83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 72.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 37.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:11<00:00, 49.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos inicializados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar Datasets e DataLoaders"
      ],
      "metadata": {
        "id": "AchbzWCOEsr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Critério de perda\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Treinar ResNet50\n",
        "optimizer_resnet = optim.Adam(resnet50.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando ResNet50...\")\n",
        "resnet50, history_resnet, best_acc_resnet = train_model(\n",
        "    model=resnet50,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_resnet,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_resnet50.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zyzDtepygmV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee6079d-fde0-4be5-b0a5-c530c569b55f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Treinando ResNet50...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0636 | Train Acc: 0.9809\n",
            "Val Loss: 0.0363 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_resnet50.pth\n",
            "⏱️ Tempo da época: 1287.3s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0012 | Train Acc: 1.0000\n",
            "Val Loss: 0.0010 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 1234.7s\n",
            "\n",
            "Época 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0008 | Train Acc: 1.0000\n",
            "Val Loss: 0.0007 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 1212.2s\n",
            "\n",
            "Época 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0006 | Train Acc: 1.0000\n",
            "Val Loss: 0.0005 | Val Acc: 1.0000\n",
            "⏹️ Early stopping ativado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_resnet50.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "metadata": {
        "id": "VXiy8-UuRIJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02af48b-80c5-4acd-bf26-8c8596d2e51c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Exportando modelos para o Google Drive...\n",
            "'best_resnet50.pth' exportado com sucesso para '/content/drive/MyDrive/ClothingDataset/TrainedModels'\n",
            "\n",
            " Exportação de modelos concluída.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar VGG16\n",
        "optimizer_vgg = optim.Adam(vgg16.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando VGG16...\")\n",
        "vgg16, history_vgg, best_acc_vgg = train_model(\n",
        "    model=vgg16,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_vgg,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_vgg16.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "FeWY8VZ2Qy7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0657385-8812-447f-aa00-ee22de4c7701"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Treinando VGG16...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0137 | Train Acc: 0.9958\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_vgg16.pth\n",
            "⏱️ Tempo da época: 5805.4s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0000 | Train Acc: 1.0000\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 3587.3s\n",
            "\n",
            "Época 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0000 | Train Acc: 1.0000\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 3625.7s\n",
            "\n",
            "Época 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0000 | Train Acc: 1.0000\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "⏹️ Early stopping ativado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_vgg16.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "metadata": {
        "id": "HxSGG58bRDhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e2f16c-f366-4aeb-866a-ae3b32d2893a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Exportando modelos para o Google Drive...\n",
            "'best_vgg16.pth' exportado com sucesso para '/content/drive/MyDrive/ClothingDataset/TrainedModels'\n",
            "\n",
            " Exportação de modelos concluída.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar EfficientNet-B0\n",
        "optimizer_efficient = optim.Adam(efficientnet.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando EfficientNet-B0...\")\n",
        "efficientnet, history_efficient, best_acc_efficient = train_model(\n",
        "    model=efficientnet,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_efficient,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_efficientnet.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "uTMIhaaVQzhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f05b6c-1492-41a9-d8c1-5a7d3aab1adf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Treinando EfficientNet-B0...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1291 | Train Acc: 0.9821\n",
            "Val Loss: 0.2891 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_efficientnet.pth\n",
            "⏱️ Tempo da época: 533.3s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0081 | Train Acc: 1.0000\n",
            "Val Loss: 0.0272 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 567.6s\n",
            "\n",
            "Época 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0037 | Train Acc: 1.0000\n",
            "Val Loss: 0.0123 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 560.8s\n",
            "\n",
            "Época 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0023 | Train Acc: 1.0000\n",
            "Val Loss: 0.0031 | Val Acc: 1.0000\n",
            "⏹️ Early stopping ativado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3924421",
        "outputId": "e3d9d029-dba9-477e-8e40-539427d695a7"
      },
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_efficientnet.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Exportando modelos para o Google Drive...\n",
            "'best_efficientnet.pth' exportado com sucesso para '/content/drive/MyDrive/ClothingDataset/TrainedModels'\n",
            "\n",
            " Exportação de modelos concluída.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparação da Acurácia de Validação\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history_resnet['val_acc'], label=\"ResNet50\")\n",
        "plt.plot(history_efficient['val_acc'], label=\"EfficientNet-B0\")\n",
        "plt.plot(history_vgg['val_acc'], label=\"VGG16\")\n",
        "plt.title(\"Comparação da Acurácia de Validação\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Resultados finais:\")\n",
        "print(f\"ResNet50 - Melhor Val Acc: {best_acc_resnet:.4f}\")\n",
        "print(f\"EfficientNet-B0 - Melhor Val Acc: {best_acc_efficient:.4f}\")\n",
        "print(f\"VGG16 - Melhor Val Acc: {best_acc_vgg:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "QgNq3h8xbxtd",
        "outputId": "dad44cc2-fab1-456b-db15-9f1560b47cce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Resultados finais:\n",
            "ResNet50 - Melhor Val Acc: 1.0000\n",
            "EfficientNet-B0 - Melhor Val Acc: 1.0000\n",
            "VGG16 - Melhor Val Acc: 1.0000\n"
          ]
        }
      ]
    }
  ]
}
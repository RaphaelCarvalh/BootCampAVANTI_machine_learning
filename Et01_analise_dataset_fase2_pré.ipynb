{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphaelCarvalh/BootCampAVANTI_machine_learning/blob/ativ04-et01-analise-dataset/Et01_analise_dataset_fase2_pr%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projeto Clothing Co-Parsing - Etapa 1 - Notebook: Análise do Dataset - TIV-04-ET-02\n"
      ],
      "metadata": {
        "id": "xB_DWEsu5T-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Projeto Clothing Co-Parsing - Notebook Principal (Professor)\n",
        "# ============================================================\n",
        "\n",
        "# 1. Instalação de pacotes necessários\n",
        "print(\"Instalando pacotes necessários...\")\n",
        "!pip install opendatasets pandas matplotlib opencv-python pillow --quiet\n",
        "print(\"Pacotes instalados com sucesso.\\n\")\n",
        "\n",
        "# 2. Importações iniciais\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time, copy, json\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Pacotes importados com sucesso.\\n\")\n",
        "\n",
        "# Otimização no CUDA\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojaVnMRr-9fR",
        "outputId": "017ca7e7-53e0-49c4-98d0-1a9042bd503d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando pacotes necessários...\n",
            "Pacotes instalados com sucesso.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Montar Google Drive e carregar dataset já limpo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "LOAD_PATH = \"/content/drive/MyDrive/ClothingDataset/df_clean.csv\"\n",
        "df = pd.read_csv(LOAD_PATH)\n",
        "\n",
        "print(\"Exemplo do dataset carregado:\")\n",
        "print(df.head())\n",
        "print(f\"Total de imagens: {len(df)}\\n\")\n",
        "\n",
        "# Número de classes\n",
        "num_classes = len(df['label'].unique())\n",
        "print(f\"Número de classes: {num_classes}\")\n"
      ],
      "metadata": {
        "id": "TE7vaTD-_BQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Transformações e Augmentations\n",
        "print(\"Configurando transformações e augmentations...\\n\")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Transformações configuradas com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQqMqZ4B_Hg9",
        "outputId": "5fb60ee6-5caa-43c9-dfd4-67c527291f89"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurando transformações e augmentations...\n",
            "\n",
            "Transformações configuradas com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Dataset personalizado\n",
        "class ClothingDataset(Dataset):\n",
        "    def __init__(self, data, transform):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx, 0], self.data[idx, 1]\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            # fallback para imagens corrompidas\n",
        "            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# 6. Split em treino, validação, teste\n",
        "train_data, temp_data = train_test_split(df.values, test_size=0.2, random_state=42, stratify=df.values[:,1])\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data[:,1])\n",
        "\n",
        "# Criar datasets\n",
        "train_ds = ClothingDataset(train_data, transform=train_transform)\n",
        "val_ds = ClothingDataset(val_data, transform=val_test_transform)\n",
        "test_ds = ClothingDataset(test_data, transform=val_test_transform)\n",
        "\n",
        "# Criar dataloaders\n",
        "BATCH_SIZE = 32\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Treino: {len(train_ds)} | Validação: {len(val_ds)} | Teste: {len(test_ds)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzaQ9EZw_Ji7",
        "outputId": "0f343c46-5f8e-40fc-af90-22daac723b6d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treino: 1676 | Validação: 210 | Teste: 210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=10,\n",
        "    device=None,\n",
        "    save_path=\"best_model.pth\",\n",
        "    early_stopping_patience=None,\n",
        "    grad_clip=None,\n",
        "    use_amp=True\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler() if (use_amp and device.type == \"cuda\") else None\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print(f\"\\nÉpoca {epoch}/{num_epochs}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # ---------- Treino ----------\n",
        "        model.train()\n",
        "        train_loss, train_correct, total = 0.0, 0, 0\n",
        "        for inputs, labels in tqdm(train_dl, desc=\"Treinando\", leave=False):\n",
        "            #inputs, labels = inputs.to(device), torch.tensor(labels, dtype=torch.long).to(device)\n",
        "            inputs, labels = inputs.to(device), labels.detach().clone().to(device, dtype=torch.long)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                scaler.scale(loss).backward()\n",
        "                if grad_clip:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                if grad_clip:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_correct += torch.sum(preds == labels).item()\n",
        "            total += inputs.size(0)\n",
        "\n",
        "        epoch_loss = train_loss / total\n",
        "        epoch_acc = train_correct / total\n",
        "        history[\"train_loss\"].append(epoch_loss)\n",
        "        history[\"train_acc\"].append(epoch_acc)\n",
        "\n",
        "        # ---------- Validação ----------\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_dl:\n",
        "                #inputs, labels = inputs.to(device), torch.tensor(labels, dtype=torch.long).to(device)\n",
        "                inputs, labels = inputs.to(device), labels.detach().clone().to(device, dtype=torch.long)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                val_correct += torch.sum(preds == labels).item()\n",
        "                val_total += inputs.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Salvar melhor modelo\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_wts, save_path)\n",
        "            patience_counter = 0\n",
        "            print(f\"✅ Melhor modelo salvo em {save_path}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if early_stopping_patience and patience_counter >= early_stopping_patience:\n",
        "                print(\"⏹️ Early stopping ativado.\")\n",
        "                break\n",
        "\n",
        "        print(f\"⏱️ Tempo da época: {(time.time()-start_time):.1f}s\")\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history, best_val_acc\n"
      ],
      "metadata": {
        "id": "DBpI-wKGW8Si"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformações e augmentations"
      ],
      "metadata": {
        "id": "XydGTCU9D7ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Definição dos modelos\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# ResNet50\n",
        "resnet50 = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "in_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(in_features, num_classes)\n",
        "resnet50 = resnet50.to(device)\n",
        "\n",
        "# EfficientNet-B0\n",
        "efficientnet = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
        "in_features = efficientnet.classifier[1].in_features\n",
        "efficientnet.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "# VGG16\n",
        "vgg16 = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
        "in_features = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Linear(in_features, num_classes)\n",
        "vgg16 = vgg16.to(device)\n",
        "\n",
        "print(\"Modelos inicializados com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjh_uGUfD6bi",
        "outputId": "8334caf9-cd1c-4c79-dd7b-886e322032e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n",
            "Modelos inicializados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar Datasets e DataLoaders"
      ],
      "metadata": {
        "id": "AchbzWCOEsr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Critério de perda\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Treinar ResNet50\n",
        "optimizer_resnet = optim.Adam(resnet50.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando ResNet50...\")\n",
        "resnet50, history_resnet, best_acc_resnet = train_model(\n",
        "    model=resnet50,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_resnet,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_resnet50.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zyzDtepygmV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511bbc0e-a12a-48f2-a6a8-84826073ad84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Treinando ResNet50...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0271 | Train Acc: 1.0000\n",
            "Val Loss: 0.0049 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_resnet50.pth\n",
            "⏱️ Tempo da época: 1149.4s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0006 | Train Acc: 1.0000\n",
            "Val Loss: 0.0005 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 1137.9s\n",
            "\n",
            "Época 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0004 | Train Acc: 1.0000\n",
            "Val Loss: 0.0003 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 1131.6s\n",
            "\n",
            "Época 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0003 | Train Acc: 1.0000\n",
            "Val Loss: 0.0003 | Val Acc: 1.0000\n",
            "⏹️ Early stopping ativado.\n",
            "\n",
            " Treinando EfficientNet-B0...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1069 | Train Acc: 0.9916\n",
            "Val Loss: 0.0071 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_efficientnet.pth\n",
            "⏱️ Tempo da época: 516.5s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0061 | Train Acc: 1.0000\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 515.2s\n",
            "\n",
            "Época 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0031 | Train Acc: 1.0000\n",
            "Val Loss: 0.0050 | Val Acc: 1.0000\n",
            "⏱️ Tempo da época: 512.8s\n",
            "\n",
            "Época 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0020 | Train Acc: 1.0000\n",
            "Val Loss: 0.0049 | Val Acc: 1.0000\n",
            "⏹️ Early stopping ativado.\n",
            "\n",
            " Treinando VGG16...\n",
            "\n",
            "Época 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0153 | Train Acc: 0.9922\n",
            "Val Loss: 0.0000 | Val Acc: 1.0000\n",
            "✅ Melhor modelo salvo em best_vgg16.pth\n",
            "⏱️ Tempo da época: 6827.0s\n",
            "\n",
            "Época 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_resnet50.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "metadata": {
        "id": "VXiy8-UuRIJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar VGG16\n",
        "optimizer_vgg = optim.Adam(vgg16.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando VGG16...\")\n",
        "vgg16, history_vgg, best_acc_vgg = train_model(\n",
        "    model=vgg16,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_vgg,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_vgg16.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "FeWY8VZ2Qy7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_vgg16.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "metadata": {
        "id": "HxSGG58bRDhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar EfficientNet-B0\n",
        "optimizer_efficient = optim.Adam(efficientnet.parameters(), lr=1e-4)\n",
        "print(\"\\n Treinando EfficientNet-B0...\")\n",
        "efficientnet, history_efficient, best_acc_efficient = train_model(\n",
        "    model=efficientnet,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_efficient,\n",
        "    num_epochs=10,\n",
        "    device=device,\n",
        "    save_path=\"best_efficientnet.pth\",\n",
        "    early_stopping_patience=3\n",
        ")\n"
      ],
      "metadata": {
        "id": "uTMIhaaVQzhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "a3924421",
        "outputId": "b94ba3ff-e9bc-4ecd-e946-dea1e1768674"
      },
      "source": [
        "# 7. Exportar modelos para o Google Drive\n",
        "print(\"\\n Exportando modelos para o Google Drive...\")\n",
        "\n",
        "EXPORT_PATH = \"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "model_files = [\"best_efficientnet.pth\"]\n",
        "\n",
        "for file_name in model_files:\n",
        "    source_path = os.path.join(\"/content/\", file_name)\n",
        "    destination_path = os.path.join(EXPORT_PATH, file_name)\n",
        "    try:\n",
        "        # Usar a função copy2 para preservar metadados\n",
        "        import shutil\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"'{file_name}' exportado com sucesso para '{EXPORT_PATH}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: O arquivo '{file_name}' não foi encontrado.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao exportar '{file_name}': {e}\")\n",
        "\n",
        "print(\"\\n Exportação de modelos concluída.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Exportando modelos para o Google Drive...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4063317661.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEXPORT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ClothingDataset/TrainedModels\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPORT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"best_resnet50.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_efficientnet.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_vgg16.pth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def evaluate_model(model, test_dl, device, class_names):\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_dl:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            true.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Relatório de métricas\n",
        "    print(classification_report(true, preds, target_names=class_names))\n",
        "\n",
        "    # Matriz de confusão\n",
        "    cm = confusion_matrix(true, preds)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predição\")\n",
        "    plt.ylabel(\"Verdadeiro\")\n",
        "    plt.title(\"Matriz de Confusão\")\n",
        "    plt.show()\n",
        "\n",
        "# Carregar os melhores pesos salvos\n",
        "resnet50.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
        "efficientnet.load_state_dict(torch.load(\"best_efficientnet.pth\"))\n",
        "vgg16.load_state_dict(torch.load(\"best_vgg16.pth\"))\n",
        "\n",
        "print(\"\\n Avaliando ResNet50 no conjunto de teste...\")\n",
        "evaluate_model(resnet50, test_dl, device, class_names)\n",
        "\n",
        "print(\"\\nAvaliando EfficientNet-B0 no conjunto de teste...\")\n",
        "evaluate_model(efficientnet, test_dl, device, class_names)\n",
        "\n",
        "print(\"\\n Avaliando VGG16 no conjunto de teste...\")\n",
        "evaluate_model(vgg16, test_dl, device, class_names)\n"
      ],
      "metadata": {
        "id": "2U9YeupvKz11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "def get_metrics(model, test_dl, device, class_names):\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_dl:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            true.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(true, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true, preds, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "# Avaliar cada modelo\n",
        "metrics = {}\n",
        "metrics[\"ResNet50\"] = get_metrics(resnet50, test_dl, device, class_names)\n",
        "metrics[\"EfficientNet-B0\"] = get_metrics(efficientnet, test_dl, device, class_names)\n",
        "metrics[\"VGG16\"] = get_metrics(vgg16, test_dl, device, class_names)\n",
        "\n",
        "# Criar DataFrame para organizar resultados\n",
        "df_metrics = pd.DataFrame(metrics, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]).T\n",
        "print(df_metrics)\n",
        "\n",
        "# Plot comparativo\n",
        "df_metrics.plot(kind=\"bar\", figsize=(10,6))\n",
        "plt.title(\"Comparação de Desempenho dos Modelos no Conjunto de Teste\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vffCdPHmK6TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "def get_metrics(model, test_dl, device, class_names):\n",
        "    model.eval()\n",
        "    preds, true = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_dl:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            true.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(true, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true, preds, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "# Avaliar cada modelo\n",
        "metrics = {}\n",
        "metrics[\"ResNet50\"] = get_metrics(resnet50, test_dl, device, class_names)\n",
        "metrics[\"EfficientNet-B0\"] = get_metrics(efficientnet, test_dl, device, class_names)\n",
        "metrics[\"VGG16\"] = get_metrics(vgg16, test_dl, device, class_names)\n",
        "\n",
        "# Criar DataFrame\n",
        "df_metrics = pd.DataFrame(metrics, index=[\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]).T\n",
        "print(\" Métricas comparativas:\\n\")\n",
        "print(df_metrics, \"\\n\")\n",
        "\n",
        "# Plot comparativo\n",
        "df_metrics.plot(kind=\"bar\", figsize=(10,6))\n",
        "plt.title(\"Comparação de Desempenho dos Modelos no Conjunto de Teste\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# --- Análise automática ---\n",
        "print(\" Análise Automática dos Resultados:\")\n",
        "for metric in df_metrics.columns:\n",
        "    best_model = df_metrics[metric].idxmax()\n",
        "    best_score = df_metrics[metric].max()\n",
        "    print(f\"- {best_model} teve o melhor {metric} ({best_score:.4f})\")\n",
        "\n",
        "print(\"\\n Interpretação geral:\")\n",
        "print(\"O modelo com maior equilíbrio entre as métricas pode ser considerado o mais robusto.\")\n",
        "print(\"Se precisão for mais importante → olhar Precision;\")\n",
        "print(\"Se cobertura for prioridade → olhar Recall;\")\n",
        "print(\"Se queremos equilíbrio → olhar F1-Score.\")\n"
      ],
      "metadata": {
        "id": "OFdLn41XLIJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Transformar modelo em extrator de features\n",
        "feature_extractor = models.resnet18(weights=\"IMAGENET1K_V1\")  # pode trocar por resnet50\n",
        "feature_extractor.fc = nn.Identity()\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "# 2. Extrair embeddings\n",
        "X, y = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(test_dl, desc=\"Extraindo embeddings\"):\n",
        "        imgs = imgs.to(device)\n",
        "        feats = feature_extractor(imgs)  # vetor de features\n",
        "        X.append(feats.cpu().numpy())\n",
        "        y.extend(labels.numpy())\n",
        "\n",
        "import numpy as np\n",
        "X = np.vstack(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Embeddings extraídos: {X.shape}, Labels: {y.shape}\")\n",
        "\n",
        "# 3. Treinar árvore de decisão\n",
        "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree_clf.fit(X, y)\n",
        "\n",
        "# 4. Plotar árvore\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(tree_clf, filled=True, feature_names=[f\"f{i}\" for i in range(X.shape[1])],\n",
        "          class_names=class_names, rounded=True, fontsize=8)\n",
        "plt.show()\n",
        "\n",
        "# 5. Avaliar árvore\n",
        "y_pred = tree_clf.predict(X)\n",
        "acc = accuracy_score(y, y_pred)\n",
        "print(f\" Acurácia da Árvore de Decisão (mesmos dados usados no fit): {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "RJ-65GBrLQb7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}